# ë‹¨ì¼ ì¶œë ¥ ì±„ë„ì„ ì´ìš©í•œ í¬ë™ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•

ì°¸ì¡°ì½”ë“œ : 

[https://github.com/4uiiurz1/pytorch-nested-unet](https://github.com/4uiiurz1/pytorch-nested-unet)

# UNet ëª¨ë¸ì„ í™œìš©í•œ ë‹¨ì¼ì¶œë ¥ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰

### **Data**

- **CRACKTREE 200 CRKWH100 CRACKLS315**

### Data Processing

- **albumentations Normalize**
    - mean = 0.535
    - std = 0.135
- **albumentations RandomRotation90**
- **albumentations Flip**
- **sklearn MinMaxScaler()**
- **cv2 CLAHE**

### ëª¨ë¸ êµ¬ì„±

- **UNet ëª¨ë¸**
    - **ì…ë ¥ ì±„ë„ = 3**
    - **ì¶œë ¥ ì±„ë„ = 1**
- **ë°”ê¹¥ ë ˆì´ì–´ì˜ ì¶œë ¥ì€ ë¡œê·¸ì‡(logit) ê°’ì…ë‹ˆë‹¤.**
- **ì´ ë¡œê·¸ì‡ ê°’ì€ ì‹œê·¸ëª¨ì´ë“œ(sigmoid) í•¨ìˆ˜ë¥¼ í†µí•´ í¬ë™ì¼ í™•ë¥ ê°’ì¸ 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.**
- **ë³€í™˜ëœ í™•ë¥ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.**
- **ë‹¨ì¼ì¶œë ¥ëª¨ë¸ì—ì„œëŠ” ë³€í™˜ëœ í™•ë¥ ê°’ì—ì„œ Crack  íŒë³„í•˜ëŠ” ì„ê³„ì ê°’ì´ ì¤‘ìš”í•©ë‹ˆë‹¤**

### UNet Architecture Summary

| Layer (type) | Output Shape | Param # |
| --- | --- | --- |
| UNet | [1, 1, 512, 512] | -- |
| â”œâ”€ VGGBlock: 1-1 | [1, 32, 512, 512] | -- |
| â”‚ â”œâ”€ Conv2d: 2-1 | [1, 32, 512, 512] | 896 |
| â”‚ â”œâ”€ BatchNorm2d: 2-2 | [1, 32, 512, 512] | 64 |
| â”‚ â”œâ”€ ReLU: 2-3 | [1, 32, 512, 512] | -- |
| â”‚ â”œâ”€ Conv2d: 2-4 | [1, 32, 512, 512] | 9,248 |
| â”‚ â”œâ”€ BatchNorm2d: 2-5 | [1, 32, 512, 512] | 64 |
| â”‚ â”œâ”€ ReLU: 2-6 | [1, 32, 512, 512] | -- |
| â”œâ”€ MaxPool2d: 1-2 | [1, 32, 256, 256] | -- |
| â”œâ”€ VGGBlock: 1-3 | [1, 64, 256, 256] | -- |
| â”‚ â”œâ”€ Conv2d: 2-7 | [1, 64, 256, 256] | 18,496 |
| â”‚ â”œâ”€ BatchNorm2d: 2-8 | [1, 64, 256, 256] | 128 |
| â”‚ â”œâ”€ ReLU: 2-9 | [1, 64, 256, 256] | -- |
| â”‚ â”œâ”€ Conv2d: 2-10 | [1, 64, 256, 256] | 36,928 |
| â”‚ â”œâ”€ BatchNorm2d: 2-11 | [1, 64, 256, 256] | 128 |
| â”‚ â”œâ”€ ReLU: 2-12 | [1, 64, 256, 256] | -- |
| â”œâ”€ MaxPool2d: 1-4 | [1, 64, 128, 128] | -- |
| â”œâ”€ VGGBlock: 1-5 | [1, 128, 128, 128] | -- |
| â”‚ â”œâ”€ Conv2d: 2-13 | [1, 128, 128, 128] | 73,856 |
| â”‚ â”œâ”€ BatchNorm2d: 2-14 | [1, 128, 128, 128] | 256 |
| â”‚ â”œâ”€ ReLU: 2-15 | [1, 128, 128, 128] | -- |
| â”‚ â”œâ”€ Conv2d: 2-16 | [1, 128, 128, 128] | 147,584 |
| â”‚ â”œâ”€ BatchNorm2d: 2-17 | [1, 128, 128, 128] | 256 |
| â”‚ â”œâ”€ ReLU: 2-18 | [1, 128, 128, 128] | -- |
| â”œâ”€ MaxPool2d: 1-6 | [1, 128, 64, 64] | -- |
| â”œâ”€ VGGBlock: 1-7 | [1, 256, 64, 64] | -- |
| â”‚ â”œâ”€ Conv2d: 2-19 | [1, 256, 64, 64] | 295,168 |
| â”‚ â”œâ”€ BatchNorm2d: 2-20 | [1, 256, 64, 64] | 512 |
| â”‚ â”œâ”€ ReLU: 2-21 | [1, 256, 64, 64] | -- |
| â”‚ â”œâ”€ Conv2d: 2-22 | [1, 256, 64, 64] | 590,080 |
| â”‚ â”œâ”€ BatchNorm2d: 2-23 | [1, 256, 64, 64] | 512 |
| â”‚ â”œâ”€ ReLU: 2-24 | [1, 256, 64, 64] | -- |
| â”œâ”€ MaxPool2d: 1-8 | [1, 256, 32, 32] | -- |
| â”œâ”€ VGGBlock: 1-9 | [1, 512, 32, 32] | -- |
| â”‚ â”œâ”€ Conv2d: 2-25 | [1, 512, 32, 32] | 1,180,160 |
| â”‚ â”œâ”€ BatchNorm2d: 2-26 | [1, 512, 32, 32] | 1,024 |
| â”‚ â”œâ”€ ReLU: 2-27 | [1, 512, 32, 32] | -- |
| â”‚ â”œâ”€ Conv2d: 2-28 | [1, 512, 32, 32] | 2,359,808 |
| â”‚ â”œâ”€ BatchNorm2d: 2-29 | [1, 512, 32, 32] | 1,024 |
| â”‚ â”œâ”€ ReLU: 2-30 | [1, 512, 32, 32] | -- |
| â”œâ”€ Upsample: 1-10 | [1, 512, 64, 64] | -- |
| â”œâ”€ VGGBlock: 1-11 | [1, 256, 64, 64] | -- |
| â”‚ â”œâ”€ Conv2d: 2-31 | [1, 256, 64, 64] | 1,769,728 |
| â”‚ â”œâ”€ BatchNorm2d: 2-32 | [1, 256, 64, 64] | 512 |
| â”‚ â”œâ”€ ReLU: 2-33 | [1, 256, 64, 64] | -- |
| â”‚ â”œâ”€ Conv2d: 2-34 | [1, 256, 64, 64] | 590,080 |
| â”‚ â”œâ”€ BatchNorm2d: 2-35 | [1, 256, 64, 64] | 512 |
| â”‚ â”œâ”€ ReLU: 2-36 | [1, 256, 64, 64] | -- |
| â”œâ”€ Upsample: 1-12 | [1, 256, 128, 128] | -- |
| â”œâ”€ VGGBlock: 1-13 | [1, 128, 128, 128] | -- |
| â”‚ â”œâ”€ Conv2d: 2-37 | [1, 128, 128, 128] | 442,496 |
| â”‚ â”œâ”€ BatchNorm2d: 2-38 | [1, 128, 128, 128] | 256 |
| â”‚ â”œâ”€ ReLU: 2-39 | [1, 128, 128, 128] | -- |
| â”‚ â”œâ”€ Conv2d: 2-40 | [1, 128, 128, 128] | 147,584 |
| â”‚ â”œâ”€ BatchNorm2d: 2-41 | [1, 128, 128, 128] | 256 |
| â”‚ â”œâ”€ ReLU: 2-42 | [1, 128, 128, 128] | -- |
| â”œâ”€ Upsample: 1-14 | [1, 128, 256, 256] | -- |
| â”œâ”€ VGGBlock: 1-15 | [1, 64, 256, 256] | -- |
| â”‚ â”œâ”€ Conv2d: 2-43 | [1, 64, 256, 256] | 110,656 |
| â”‚ â”œâ”€ BatchNorm2d: 2-44 | [1, 64, 256, 256] | 128 |
| â”‚ â”œâ”€ ReLU: 2-45 | [1, 64, 256, 256] | -- |
| â”‚ â”œâ”€ Conv2d: 2-46 | [1, 64, 256, 256] | 36,928 |
| â”‚ â”œâ”€ BatchNorm2d: 2-47 | [1, 64, 256, 256] | 128 |
| â”‚ â”œâ”€ ReLU: 2-48 | [1, 64, 256, 256] | -- |
| â”œâ”€ Upsample: 1-16 | [1, 64, 512, 512] | -- |
| â”œâ”€ VGGBlock: 1-17 | [1, 32, 512, 512] | -- |
| â”‚ â”œâ”€ Conv2d: 2-49 | [1, 32, 512, 512] | 27,680 |
| â”‚ â”œâ”€ BatchNorm2d: 2-50 | [1, 32, 512, 512] | 64 |
| â”‚ â”œâ”€ ReLU: 2-51 | [1, 32, 512, 512] | -- |
| â”‚ â”œâ”€ Conv2d: 2-52 | [1, 32, 512, 512] | 9,248 |
| â”‚ â”œâ”€ BatchNorm2d: 2-53 | [1, 32, 512, 512] | 64 |
| â”‚ â”œâ”€ ReLU: 2-54 | [1, 32, 512, 512] | -- |
| â”œâ”€ Conv2d: 1-18 | [1, 1, 512, 512] | 33 |
| Total params |  | 7,852,545 |
| Trainable params |  | 7,852,545 |
| Non-trainable params |  | 0 |
| Total mult-adds (G) |  | 55.87 |
| Input size (MB) |  | 3.15 |
| Forward/backward pass size (MB) |  | 1025.51 |
| Params size (MB) |  | 31.41 |
| Estimated Total Size (MB) |  | 1060.06 |

![Untitled](notion_image
/Untitled.png)

**ë§ˆì§€ë§‰ ë¶„ë¥˜ layerì˜ ì¶œë ¥ shape 1 1 512 512      [batch_size , chaneel , height , width ] ì…ë‹ˆë‹¤**               

### í‰ê°€ ë°©ë²•

- **Precision**
- **Recall**
- **F1 Score**
- **Optimal Image Scale (OIS)**
- **Optimal Dataset Scale (ODS)**

ê° ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ëŠ” ì´í•˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì™€ ê°™ìŠµë‹ˆë‹¤

```
**inputs
â””â”€â”€ DATASET
    â”œâ”€â”€ CRACKTREE260
    â”‚   â”œâ”€â”€ images
    â”‚   â”‚   â”œâ”€â”€ 00ae65... (JPEG íŒŒì¼)
    â”‚   â””â”€â”€ masks
    â”‚       â”œâ”€â”€ 00ae65... (BMP íŒŒì¼)
    â”‚
    â”œâ”€â”€ CRKWH100
    â”‚   â”œâ”€â”€ images
    â”‚   â”‚   â”œâ”€â”€ 00ae65... (png íŒŒì¼)
    â”‚   â””â”€â”€ masks
    â”‚       â”œâ”€â”€ 00ae65... (BMP íŒŒì¼)
    â”‚
    â”œâ”€â”€ CRACKLS315
    â”‚   â”œâ”€â”€ images
    â”‚   â”‚   â”œâ”€â”€ 00ae65... (JPEG íŒŒì¼)
    â”‚   â””â”€â”€ masks
    â”‚       â”œâ”€â”€ 00ae65... (BMP íŒŒì¼** 
    
```

## **ë°ì´í„°ì „ì²˜ë¦¬**

`sklearn.model_selection.train_test_split`ì„ ì´ìš©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì˜ 10%ë¥¼ validation ê²€ì¦ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

`torch.utils.data.Dataset`ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ì— ëŒ€í•´ ë™ì¼í•œ ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ê³ , ì´ë¯¸ì§€ ê°’ì˜ ë²”ìœ„ë¥¼ 0~255 â†’ 0~1 ë²”ìœ„ë¡œ ì¬ì¡°ì •í•©ë‹ˆë‹¤.

![Untitled](notion_image/Untitled%201.png)

![Untitled](notion_image/Untitled%202.png)

albumentations ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `RandomRotate90` ë° `Flip` í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„° ì¦ê°•ì„ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

ì¼ë¶€ ë°ì´í„°ì…‹ì€ `mean=0.5`, `std=0.135`ë¥¼ ì´ìš©í•˜ì—¬ ì¶”ê°€ì ì¸ ì´ë¯¸ì§€ ì •ê·œí™” ê³¼ì •ì„ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

![Untitled](notion_image/Untitled%203.png)

![Untitled](notion_image/Untitled%204.png)

ì¶”ê°€ì‹œë„: CrackTree260 ë°ì´í„°ì…‹ì€ 800 x 600 ë° 960 x 720 ì´ë¯¸ì§€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. CRKWH100ê³¼ CRACKLS315 ë°ì´í„°ì…‹ì€ 512 x 512 ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´, ì„¸ ê°€ì§€ ë°ì´í„°ì…‹ì— ë™ì¼í•œ ëª¨ë¸ì„ ì ìš©í•˜ë ¤ë©´ ë™ì¼í•œ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¬êµ¬ì„±í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ CrackTree260 ë°ì´í„°ì…‹ì˜ ì´ë¯¸ì§€ë¥¼ 512 x 512 í¬ê¸°ë¡œ ë³€ê²½í•˜ê¸° ìœ„í•´ **A.Resize(512, 512)**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì†ì‹¤ìœ¨(BCEDiceLoss)ì´ 0.35 ~ 0.4ì—ì„œ ê°œì„ ë˜ì§€ ì•ŠëŠ” ëª¨ìŠµì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ì— ë”°ë¼, ì´ë¯¸ì§€ì˜ ì „ì²´ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ëŒ€ì‹  ì¼ë¶€ë§Œ **A.RandomCrop(512)** 512 x 512 í¬ê¸°ë¡œ ì˜ë¼ë‚´ì–´ í›ˆë ¨ì„ ì§„í–‰í•˜ë‹ˆ ì†ì‹¤ìœ¨ì´ 0.25 ~ 0.3ê¹Œì§€ ê°œì„ ë˜ëŠ” ë¶€ë¶„ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Crack íƒì§€ì™€ ê°™ì€ ì¤‘ìš”í•œ ì´ë¯¸ì§€ì˜ ê²½ìš°, ë¹„ìœ¨ì ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì¤„ì´ëŠ” ê²ƒë³´ë‹¤ ì›ë³¸ ì´ë¯¸ì§€ì˜ í”½ì…€ì„ ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ë©´ì„œ ì¼ë¶€ë¶„ì„ ì˜ë¼ë‚´ëŠ” ê²ƒì´ í•™ìŠµì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤

ì°¸ê³ ì‚¬í•­: CRACK500 ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ í•™ìŠµì„ í• ë•Œ Unet ëª¨ë¸ inputìœ¼ë¡œ 640 x 640 ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ê¸°ìœ„í•´ 340 x 640 ì´ë¯¸ì§€ë¥¼ íŒ¨ë”©ì„ ì¶”ê°€í•˜ì—¬ 640 x 640 ì´ë¯¸ì§€ë¡œ êµ¬ì„±í•˜ì—¬ í•™ìŠµí•˜ì˜€ë”ë‹ˆ ì¢‹ì€ì„±ëŠ¥ì„ ì–»ì—ˆìŠµë‹ˆë‹¤

[ë°”ì´ë„ˆë¦¬ ì¶œë ¥ì„ ì´ìš©í•œ í¬ë™ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë°©ë²•](https://www.notion.so/3395d3198b744928ac72985be0ab8054?pvs=21) 

![pad_image.jpg](notion_image/pad_image.jpg)

![pd_mask.png](notion_image/pd_mask.png)

```python
class Dataset_min_max(torch.utils.data.Dataset):

    def __init__(self, img_ids, img_dir, mask_dir, img_ext, mask_ext, num_classes, transform=None):
        self.img_ids = img_ids
        self.img_dir = img_dir
        self.mask_dir = mask_dir
        self.img_ext = img_ext
        self.mask_ext = mask_ext
        self.num_classes = num_classes
        self.transform = Compose([
            A.RandomRotate90(),
            A.Flip(),
            A.RandomCrop(height=512,width=512)
        ])
        
        self.scaled = MinMaxScaler()
        
    def __len__(self):
        return len(self.img_ids)

    def __getitem__(self, idx):
        img_id = self.img_ids[idx]
        
        img = cv2.imread(os.path.join(self.img_dir, img_id +'.' + self.img_ext),cv2.IMREAD_COLOR)
        mask = cv2.imread(os.path.join(self.mask_dir , img_id +'.'+self.mask_ext),cv2.IMREAD_GRAYSCALE)
        
        if img is None or mask is None:
            raise FileExistsError()
        
        
        if self.transform is not None:
            augmented = self.transform(image=img, mask=mask)
            img = augmented['image']
            mask = augmented['mask']
            img = self.__min_max_convert(img)

            
        img = img.transpose(2, 0, 1)
        mask = mask.astype('float32') / 255
        mask = np.expand_dims(mask , axis=0)
        
        if np.all( img == 0 ): 
            raise Exception(f"image All Elemnets is None")
        
        assert img.shape[1:] == mask.shape[1:], f"not same image shape: img shape {img.shape}, mask shape {mask.shape}"
        
        img = torch.Tensor(img)
        mask = torch.Tensor(mask)
        return img, mask 
    
    def __min_max_convert(self,image:np.array):
        h,w,c = image.shape
        
        image_reshaped = image.reshape(-1,1)
        min_max_scaler = self.scaled
        image_scaled = min_max_scaler.fit_transform(image_reshaped)
        image_scaled = image_scaled.reshape(h,w,c)
        
```

## Model Training

- **Loss Function**:  BCEDiceLoss â†’ BCEWithLogitLoss + Dice ì„ ì‚¬ìš©í•©ë‹ˆë‹¤

$$
ğ·ğ‘–ğ‘ğ‘’=2âˆ—âˆ£ğ´âˆ©ğµâˆ£/âˆ£ğ´âˆ£+âˆ£ğµâˆ£=2âˆ—ğ‘‡ğ‘ƒ(ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ)+(ğ‘‡ğ‘ƒ+ğ¹ğ‘)                
$$

ì¶”ê°€ì‹œë„ : Focal Loss, Binary Cross-Entropy, Dice Loss ì„¸ ê°€ì§€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë™ì¼í•œ ëª¨ë¸ê³¼ ë™ì¼í•œ Optimizerì—ì„œ í›ˆë ¨ì„ ì§„í–‰í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

- **Focal Loss**: ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¡œ, í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì–´ë µê²Œ ë¶„ë¥˜ë˜ëŠ” ìƒ˜í”Œì— ë” ë§ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ê³ , ì‰½ê²Œ ë¶„ë¥˜ë˜ëŠ” ìƒ˜í”Œì—ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    
    â†’ Crack ë°ì´í„°ì…‹ì€ ë ˆì´ë¸” ê°’ì´ 0 (Non-crack)ê³¼ 1 (Crack)ë¡œ êµ¬ì„±ë˜ë©°, ëŒ€ë¶€ë¶„ì˜ ì´ë¯¸ì§€ëŠ” Non-Crack (0)ì¸ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œê°€ ìˆë‹¤ê³  íŒë‹¨í•˜ì—¬ Focal Lossë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„ ì‹œë„í•˜ì˜€ìœ¼ë‚˜, ì´ˆê¸°ë¶€í„° ë‚®ì€ ì†ì‹¤ìœ¨ì„ ë³´ì—¬ì£¼ì—ˆê³ , ì†ì‹¤ìœ¨ì´ ë‚®ì§€ë§Œ í‰ê°€ ì§€í‘œì™€ ì‹œê°í™”ë¥¼ ì§„í–‰í–ˆì„ ë•Œ í•™ìŠµì„ í•˜ì§€ ëª»í•œ ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
    
- **Binary Cross-Entropy**: ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë ˆì´ë¸” ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ ì´ ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì–¼ë§ˆë‚˜ ê°€ê¹Œìš´ì§€ë¥¼ í‰ê°€í•˜ì—¬, ëª¨ë¸ì´ ì˜ˆì¸¡ì„ ê°œì„ í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    â†’ BCE ì†ì‹¤ í•¨ìˆ˜ëŠ” ì´ì§„ ë¶„ë¥˜ì— íŠ¹í™”ë˜ì–´ ìˆìœ¼ë©°, ë¡œê·¸ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì´ í¬ê²Œ ë‹¤ë¥¼ ë•Œ ì†ì‹¤ í•¨ìˆ˜ê°€ í¬ê²Œ ì¦ê°€í•˜ì—¬ ëª¨ë¸ì˜ í•™ìŠµì´ ì˜¬ë°”ë¥´ê²Œ ì§„í–‰ë˜ë„ë¡ í•©ë‹ˆë‹¤. BCEë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•œ ê²½ìš°, Focal Lossë³´ë‹¤ëŠ” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë‚˜, ì†ì‹¤ìœ¨ì´ 0.4ì—ì„œ ê°ì†Œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    

```python
 class BCEDiceLoss(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, input, target):
        bce = F.binary_cross_entropy_with_logits(input, target)
        smooth = 1e-5
        input = torch.sigmoid(input)
        num = target.size(0)
        input = input.view(num, -1)
        target = target.view(num, -1)
        intersection = (input * target)
        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)
        dice = 1 - dice.sum() / num
        return 0.5 * bce + dice
```

- **Optimizer**: Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ì˜€ìœ¼ë©°, ê¸°ë³¸ Learning rateëŠ” 1e-2, weight_decayëŠ” 1e-4ë¡œ ì„¤ì •í•˜ì—¬ íŠ¹ì • ê°€ì¤‘ì¹˜ì˜ ì—…ë°ì´íŠ¸ ë²”ìœ„ë¥¼ ì œí•œí•˜ì˜€ìŠµë‹ˆë‹¤.
- **L2 ê·œì œí™”**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì†ì‹¤ê°’ì— ê°€ì¤‘ì¹˜ë“¤ì˜ ì œê³±ì„ ì¶”ê°€í•˜ì—¬, ê°€ì¤‘ì¹˜ê°€ í° í­ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë  ë•Œ ê·œì œë¥¼ í†µí•´ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤.

```python
  optimizer = optim.Adam(params , lr = 1e-2 , weight_decay=1e-4] )

```

$$
L(W)=1/Nâˆ‘(yiâˆ’W^tXi)^2+Î»âˆ‘Wj^2
$$

- **Learning Rate Scheduler**:í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì¼ì • íšŸìˆ˜ ë™ì•ˆ ì†ì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ 10ë²ˆ ë™ì•ˆ ì†ì‹¤ë¥  ê°œì„ ì´ ì—†ì„ ë•Œ ê¸°ì¡´ Learning rateì—ì„œ factorë§Œí¼ ìƒˆë¡œìš´ Learning rateë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤
- (`torch.optim.lr_scheduler.ReduceLROnPlateau`)
    - `mode="min"`
    - `patience=10`
    - `min_lr=1e-8`
    - `factor=0.1`

- **Metrics**: ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall), F1 ìŠ¤ì½”ì–´ë¥¼ í†µí•´ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.

```python
    for epoch in range(config['epochs']):
        print('Epoch [%d/%d]' % (epoch, config['epochs']))

        # train for one epoch
        train_log = train(config, train_loader, model, criterion, optimizer)
        writer.add_scalar('loss/train',train_log['loss'] , epoch)
        
        writer.add_scalar('iou/train' , train_log['iou'] , epoch)
        
        # evaluate on validation set
        val_log = validate(config, val_loader, model, criterion)
        writer.add_scalar('loss/val',val_log['loss'] , epoch)
        writer.add_scalar('iou/val', val_log['iou'] , epoch)
        
        if config['scheduler'] == 'CosineAnnealingLR':
            scheduler.step()
        elif config['scheduler'] == 'ReduceLROnPlateau':
            scheduler.step(val_log['loss'])
 
        print('loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f Learing Rate %e'
              % (train_log['loss'], train_log['iou'], val_log['loss'], val_log['iou'] , scheduler.get_last_lr()[0]))

        log['epoch'].append(epoch)
        
    def train(config, train_loader, model, criterion, optimizer):
		    logging.info(("\n" + "%12s" * 3) % ("Epoch", "GPU Mem", "Loss"))
		        
		    avg_meters = {'loss': AverageMeter(),
		                  'iou': AverageMeter()}
		
		    model.train()
		
		    pbar = tqdm(total=len(train_loader))
		    for i , (input, target) in enumerate(train_loader):
		        input = input.cuda()
		        target = target.cuda()
		
		        # compute output
		        if config['deep_supervision']:
		            outputs = model(input)
		            loss = 0
		            for output in outputs:
		                loss += criterion(output, target)
		            loss /= len(outputs)
		            iou = iou_score(outputs[-1], target)
		        else:
		            output = model(input)
		            loss = criterion(output, target)
		            iou = iou_score(output, target)
		
		        # compute gradient and do optimizing step
		        optimizer.zero_grad()
		        loss.backward()
		        optimizer.step()
```

# **U net ëª¨ë¸êµ¬ì¡° ì„¤ëª…**

```python
class VGGBlock(nn.Module):
    def __init__(self, in_channels, middle_channels, out_channels):
        super().__init__()
        self.relu = nn.ReLU(inplace=True)
        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(middle_channels)
        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        return out
```

VGGBlockì—ì„œëŠ” Double(Conv2d)ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤. í•˜ë‚˜ì˜ Convolution ì—°ì‚°ì´ ìˆ˜í–‰ë  ë•Œë§ˆë‹¤ batchNorm ê³¼ì •ê³¼ ReLU í™œì„±í™” í•¨ìˆ˜ê°€ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

```python
class UNet(nn.Module):
    def __init__(self, num_classes, input_channels=3, **kwargs):
        super().__init__()

        nb_filter = [32, 64, 128, 256, 512]

        self.pool = nn.MaxPool2d(2, 2)
        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])
        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])
        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])
        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])
        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])

        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])
        self.conv2_2 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])
        self.conv1_3 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])
        self.conv0_4 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])

        self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)

    def forward(self, input):
        x0_0 = self.conv0_0(input)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x2_0 = self.conv2_0(self.pool(x1_0))
        x3_0 = self.conv3_0(self.pool(x2_0))
        x4_0 = self.conv4_0(self.pool(x3_0))

        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))
        x2_2 = self.conv2_2(torch.cat([x2_0, self.up(x3_1)], 1))
        x1_3 = self.conv1_3(torch.cat([x1_0, self.up(x2_2)], 1))
        x0_4 = self.conv0_4(torch.cat([x0_0, self.up(x1_3)], 1))

        output = self.final(x0_4)
        return output
```

UNet ê¸°ë³¸ í´ë˜ìŠ¤ëŠ” 4ë²ˆì˜ ìˆ˜ì¶• ê³¼ì •ê³¼ 4ë²ˆì˜ í™•ì¥ ê³¼ì •ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. í™•ì¥ ê³¼ì •ì—ì„œëŠ” ìˆ˜ì¶• ê³¼ì •ì—ì„œì˜ ê²°ê³¼ë¥¼ í•©ì¹˜ë©°, ì´ì „ ê³¼ì •ì˜ ê²°ê³¼ë¥¼ ì—…ìƒ˜í”Œ(upsample) ê³¼ì •ì„ í†µí•´ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì¶”ê°€ì‹œë„ : Deep_Supervison

ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµê³¼ì •ì¤‘ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤ ê¹Šì€ì‹ ê²½ë§ì˜ ì¤‘ê°„ì¸µì—ì„œë„ ì†ì‹¤í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ í•™ìŠµê³¼ì •ì •ì—ì„œ ì •í™•ë„í–¥ìƒì— ê¸°ì—¬í•©ë‹ˆë‹¤

â†’ Deep_Supervisonì„ ì´ìš©í• ì‹œ Unetëª¨ë¸ì´ ì•„ë‹Œ Unet++ ëª¨ë¸ë¡œì¨ ë‹¤ë¥¸ ëª¨ë¸ì…ë‹ˆë‹¤

![Untitled](notion_image/Untitled%205.png)

# **ì¶”ë¡  ë° í‰ê°€**

```python
class Eval_MODE():
    def __init__(self):
        self.epsilon = 1e-7
    
    def __call__(self,model,data_loader,device):
        l = self.main(model , data_loader , device)
        return l
    @torch.inference_mode
    def main(self , model , data_loader , device):
        """input ---> model test_data_loader device <<<<"""
        model.eval()
        loss_list = []
        out_list = []
        target_list = []
        criterion = BCEDiceLoss()
        for image , target  in tqdm(data_loader , total=len(data_loader)):
            image , target = image.to(device) , target.to(device)
            with torch.no_grad():
                out = model(image)
                loss = criterion(out , target)
                loss_list.append(loss)
                out_list.append(out)
                target_list.append(target)

        it_range = np.arange(0.1 , 1.01 , 0.01)
        best_th = 0.0
        best_f = 0.0
        best_p = 0.0
        best_r = 0.0
        OIS_RES = self.get_OIS(out_list , target_list)
        for th in it_range:
            th_res , p , r , f= self.get_ODS(out_list, target_list ,th)   
            if f > best_f:
                best_f = f 
                best_th = th_res
                best_p = p
                best_r = r
        print(f"----------> ì •ë°€ë„í‰ê·  : {best_p:.5f} ì¬í˜„ìœ¨í‰ê·  : {best_r:.5f} OIS : {OIS_RES:.5f}  ODS(F1 score í‰ê· ) : {best_f:.5f}")
        return  sum(loss_list) / len(loss_list)

    def get_f1_score(self, outputs , target , th):
        outputs = torch.sigmoid(outputs)
        outputs = (outputs > th).float()
        
        TP = (outputs * target).sum().item()
        FP = (outputs * (1-target)).sum().item()
        FN = ((1-outputs) * target).sum().item()
        
        precision = TP / (TP + FP + self.epsilon)
        recall = TP / (TP + FN + self.epsilon)
        f1_score = 2 * (precision * recall) / (precision + recall + self.epsilon)
        
        return f1_score

    def find_best_threshold(self , outputs , target):
        thresholds = np.arange(0, 1.01, 0.01)
        best_f1 = 0.0
        best_thresholds = 0.0
        for i in thresholds:
            f1 = self.get_f1_score(outputs , target , i)
            #print(f"f1 : {f1} threshold : {i}")
            if f1 > best_f1:
                best_f1 = f1
                best_thresholds = i
        return best_thresholds , best_f1
    
    
    def get_OIS(self , out_list : list , target_list : list) :
        f1_list = []
        res = zip(out_list , target_list)
        for i  , (out , target) in enumerate(res):
            output = torch.sigmoid(out)
            best_th , f_ = self.find_best_threshold(output , target)
            print(f"{i}-->Threshold : {best_th:.2f} f1_score : {f_:.4f}")
            f1_list.append(f_)
            
        OIS_RESULT =  sum(f1_list) / len(f1_list)    
        return OIS_RESULT
        
        
    def get_ODS(self , out_list , target_list , th=0.5 , flag=False):
        
        precision_list = []
        recall_list = []
        f1_score_list = []
        res = zip(out_list , target_list)
        for output,target in res:
            output = torch.sigmoid(output)
            
            output = (output > th).float()
            
            TP = (output * target).sum().item()
            FP = (output * (1-target)).sum().item()
            FN = ((1-output) * target).sum().item()
            
            precision = TP / (TP + FP + 1e-7)
            recall = TP / (TP + FN + 1e-7)
            f1_score = 2 * (precision * recall) / (precision + recall + 1e-7)
            
            precision_list.append(precision)
            recall_list.append(recall)
            f1_score_list.append(f1_score)

        p = sum(precision_list) / len(precision_list)
        r = sum(recall_list) / len(recall_list)
        f = sum(f1_score_list) / len(f1_score_list)
        return th , p , r , f

```

- **Precision** : ëª¨ë¸ì´ ì–‘ì„± í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡í•œ ë°ì´í„° ì¤‘ ì‹¤ì œë¡œ ì–‘ì„±ì¸ ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤

$$
Precision=TP/TP + FP
$$

- **Recall** : ì‹¤ì œ ì–‘ì„± ë°ì´í„° ì¤‘ ëª¨ë¸ì´ ì–‘ì„±ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë°ì´í„°ì˜ ë¹„ìœ¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

$$
Recall=TP/TP+FN
$$

- **f1-Score** :  Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.

$$
F1=2â‹…Precision+Recall/Precisionâ‹…Recall
$$

- **OIS** : ê° ì´ë¯¸ì§€ì—ì„œ ìµœê³ ì˜ F1 ì ìˆ˜ë¥¼ ë°›ëŠ” ê²½ê³„ì ì„ í†µí•œ ëª¨ë“  ì´ë¯¸ì§€ì˜ F1 ì ìˆ˜ í‰ê· ê°’ì…ë‹ˆë‹¤.

- **ODS** : ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ ë™ì¼í•œ ê²½ê³„ì ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ F1 ì ìˆ˜ í‰ê· ê°’ì…ë‹ˆë‹¤.

# ê²°ê³¼ / ì •ë¦¬

CrackTree260 Tensorboard 

![Untitled](notion_image/Untitled%206.png)

ì´ˆê¸° ì†ì‹¤ìœ¨ì€ 1ì—ì„œ ì‹œì‘í•˜ì—¬ 0.35ê¹Œì§€ ê°ì†Œí•˜ëŠ” í˜„ìƒì„ ë³¼ìˆ˜ìˆìœ¼ë‚˜ ì´í›„ ê°œì„ ì´ë˜ì§€ì•ŠëŠ” í•™ìŠµì •ì²´ë¥¼ ë³¼ìˆ˜ìˆìŠµë‹ˆë‹¤ 

ì¶”ê°€ì‹œë„ : Attention Unet ëª¨ë¸ ì†ì‹¤ìœ¨ì´ 0.17ê¹Œì§€ ê°ì†Œí•˜ì˜€ìŠµë‹ˆë‹¤

![Untitled](notion_image/Untitled%207.png)

![Untitled](notion_image/Untitled%208.png)

> 3ê°€ì§€ì˜ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  í›ˆë ¨ì„ ì§„í–‰í•˜ì˜€ìœ¼ë©°, CrackTree260 ë°ì´í„°ì…‹ì€ ì¶”ê°€ì ì¸ ì „ì²˜ë¦¬ ê³¼ì •ì„ í†µí•´ ì„±ëŠ¥ í–¥ìƒì„ ê´€ì¸¡í•˜ì˜€ìŠµë‹ˆë‹¤. CrackTree260ê³¼ CRKWH100 ë°ì´í„°ì…‹ì€ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„°ì…‹ì˜ ì„±ëŠ¥ì„ ì¶”ê°€ì ìœ¼ë¡œ ê²€ì¦í•˜ì˜€ìŠµë‹ˆë‹¤.
> 
> 
> ---
> 

## CRACKTREE260

![Untitled](notion_image/Untitled%209.png)

![Untitled](notion_image/Untitled%2010.png)

CRACKTREE â†’ CRKWH100

![Untitled](notion_image/Untitled%2011.png)

CRACKTREE - > CRACKLS315

![Untitled](notion_image/Untitled%2012.png)

## CRACKTree260 Norm ìˆ˜í–‰ Mean 0.5 std 0.135

![Untitled](notion_image/Untitled%2013.png)

![Untitled](notion_image/Untitled%2014.png)

CRACKTREE â†’ CRKWH 100

![Untitled](notion_image/Untitled%2015.png)

CRACKTREE â†’ CRACKLS315

![Untitled](notion_image/Untitled%2016.png)

## í‰í™œí™” CLAHE(Contrast Limited Adaptive Histogram Equalization) ìˆ˜í–‰

íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”ë¥¼ í†µí•´ ëª…ì•”ëŒ€ë¹„ë¥¼ ê°œì„ í•˜ì˜€ìŠµë‹ˆë‹¤. CLAHEëŠ” ì´ë¯¸ì§€ì˜ ëª…ì•”ëŒ€ë¹„ë¥¼ êµ­ë¶€ì ìœ¼ë¡œ ê°œì„ í•˜ì—¬ ì„¸ë¶€ ì‚¬í•­ì„ ë” ì˜ ë³´ì´ê²Œ í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì „ì²´ì ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ë””í…Œì¼ì„ í–¥ìƒì‹œí‚¤ë©°, íŠ¹íˆ ì¡°ëª… ì¡°ê±´ì´ ê· ì¼í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì—ì„œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

![Untitled](notion_image/Untitled%2017.png)

CRACK TREE

![Untitled](notion_image/Untitled%2018.png)

CRKWH 100

![ìŠ¤í¬ë¦°ìƒ· 2024-07-26 12-32-42.png](notion_image
/%25EC%258A%25A4%25ED%2581%25AC%25EB%25A6%25B0%25EC%2583%25B7_2024-07-26_12-32-42.png)

CRACKLS315

![Untitled](notion_image/Untitled%2019.png)

## **CRKWH100**

![Untitled](notion_image/Untitled%2020.png)

![Untitled](notion_image/Untitled%2021.png)

CRKWH100 â†’ CRACKTREE

![Untitled](notion_image/Untitled%2022.png)

CRKWH100 â†’ CRACKLS315

![Untitled](notion_image/Untitled%2023.png)

## **CRACKLS315**

![Untitled](notion_image/Untitled%2024.png)

![Untitled](notion_image/Untitled%2025.png)